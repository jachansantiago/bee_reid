{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow_addons.losses import TripletSemiHardLoss, TripletHardLoss\n",
    "from beeid2.data_utils import filename2image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TEST_CSV = \"/home/jchan/beeid/notebooks/cmc_experiments/data/test.csv\"\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "def to_np_array(values, dim=128):\n",
    "    return np.concatenate(list(values)).reshape(-1, dim)\n",
    "\n",
    "def get_shortterm_mean_dist(test_df):    \n",
    "    gtracks = test_df.groupby(\"global_track_id\").filter(lambda x: len(x) > 1)\n",
    "    means = list()\n",
    "    for tid in gtracks.global_track_id.unique():\n",
    "        track_embs = gtracks[gtracks.global_track_id == tid].emb.values\n",
    "        track_embs = to_np_array(track_embs)\n",
    "        dmatrix = 1 - tf.matmul(track_embs, track_embs.T).numpy()\n",
    "        distances = dmatrix[np.triu_indices(dmatrix.shape[0], k = 1)].mean()\n",
    "        means.append(distances)\n",
    "    return np.mean(means), means\n",
    "\n",
    "def get_longterm_mean_dist(test_df):\n",
    "    timegap=15\n",
    "    timegap_unit=\"m\"\n",
    "    gtracks = test_df.groupby(\"track_tag_id\").filter(lambda x: len(x[\"global_track_id\"].unique()) > 1)\n",
    "    gtracks = gtracks.global_track_id.unique()\n",
    "\n",
    "    distances = []\n",
    "    eval_tracks = len(gtracks)\n",
    "    print(\"Evaluating {} tracks.\".format(eval_tracks))\n",
    "\n",
    "    queries_num = 0\n",
    "    tag_id_dist = defaultdict(lambda: np.array([]))\n",
    "\n",
    "    for gtrack in tqdm(gtracks):\n",
    "        is_same_track = (test_df.global_track_id == gtrack)\n",
    "        im_tracks = test_df[is_same_track]\n",
    "        query_row = im_tracks.iloc[0]\n",
    "        is_same_id = (query_row.track_tag_id == test_df.track_tag_id)\n",
    "        is_enough_timegap = np.abs(test_df.datetime2 - query_row.datetime2).astype('timedelta64[{}]'.format(timegap_unit)) > timegap\n",
    "\n",
    "        gallery_df = test_df[(is_enough_timegap & is_same_id & ~ is_same_track)]\n",
    "        if np.sum(gallery_df.track_tag_id == query_row.track_tag_id) == 0:\n",
    "            continue\n",
    "\n",
    "        tag_id = query_row.track_tag_id\n",
    "        gtrack_dist = np.array([])\n",
    "\n",
    "        gallery = to_np_array(gallery_df[\"emb\"].values)\n",
    "        for _, row in im_tracks.iterrows():\n",
    "            query_id = row.track_tag_id\n",
    "            query = np.expand_dims(row.emb, axis=0)\n",
    "            distances = 1 - tf.matmul(query, gallery.T).numpy()\n",
    "            distances = np.squeeze(distances)\n",
    "            gtrack_dist = np.append(gtrack_dist, distances)\n",
    "        tag_id_dist[tag_id] = np.append(tag_id_dist[tag_id],  gtrack_dist)\n",
    "\n",
    "    mean_per_tag_id = [np.mean(ds) for ds in tag_id_dist.values()]\n",
    "    return np.mean(mean_per_tag_id), mean_per_tag_id\n",
    "\n",
    "\n",
    "def get_notsame_mean_dist(test_df):\n",
    "    timegap=15\n",
    "    timegap_unit=\"m\"\n",
    "    gtracks = test_df.groupby(\"track_tag_id\").filter(lambda x: len(x[\"global_track_id\"].unique()) > 1)\n",
    "    gtracks = gtracks.global_track_id.unique()\n",
    "\n",
    "    distances = []\n",
    "    eval_tracks = len(gtracks)\n",
    "    print(\"Evaluating {} tracks.\".format(eval_tracks))\n",
    "\n",
    "    queries_num = 0\n",
    "    tag_id_dist = defaultdict(lambda: np.array([]))\n",
    "\n",
    "    for gtrack in tqdm(gtracks):\n",
    "        is_same_track = (test_df.global_track_id == gtrack)\n",
    "        im_tracks = test_df[is_same_track]\n",
    "        query_row = im_tracks.iloc[0]\n",
    "        is_same_id = (query_row.track_tag_id == test_df.track_tag_id)\n",
    "        is_enough_timegap = np.abs(test_df.datetime2 - query_row.datetime2).astype('timedelta64[{}]'.format(timegap_unit)) > timegap\n",
    "\n",
    "        gallery_df = test_df[~ is_same_id]\n",
    "\n",
    "        tag_id = query_row.track_tag_id\n",
    "        gtrack_dist = np.array([])\n",
    "\n",
    "        gallery = to_np_array(gallery_df[\"emb\"].values)\n",
    "        for _, row in im_tracks.iterrows():\n",
    "            query_id = row.track_tag_id\n",
    "            query = np.expand_dims(row.emb, axis=0)\n",
    "            distances = 1 - tf.matmul(query, gallery.T).numpy()\n",
    "            distances = np.squeeze(distances)\n",
    "            gtrack_dist = np.append(gtrack_dist, distances)\n",
    "        tag_id_dist[tag_id] = np.append(tag_id_dist[tag_id],  gtrack_dist)\n",
    "\n",
    "    mean_per_tag_id = [np.mean(ds) for ds in tag_id_dist.values()]\n",
    "    return np.mean(mean_per_tag_id), mean_per_tag_id\n",
    "\n",
    "def eval_model_short_long_term(model_path):\n",
    "    model = load_model(model_path, custom_objects={'tf': tf})\n",
    "\n",
    "    test_df = pd.read_csv(TEST_CSV)\n",
    "    test_df[\"datetime2\"] = pd.to_datetime(test_df[\"datetime\"])\n",
    "\n",
    "    filenames = test_df[\"filename\"].values\n",
    "    images = filename2image(filenames)\n",
    "    predictions = model.predict(images.batch(batch_size), verbose=True)\n",
    "    test_df[\"emb\"]  = list(predictions)\n",
    "\n",
    "    shortterm_mean_dist, short_distribution = get_shortterm_mean_dist(test_df)\n",
    "    longterm_mean_dist, long_distribution = get_longterm_mean_dist(test_df)\n",
    "    notsame_mean_dist, notsame_distribution = get_notsame_mean_dist(test_df)\n",
    "    return shortterm_mean_dist, short_distribution, longterm_mean_dist, long_distribution, notsame_mean_dist, notsame_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = defaultdict(dict)\n",
    "ntracks = [181, 362, 724, 1448, 2896, 4949]\n",
    "for ntrack in ntracks:\n",
    "    model_path = \"/home/jchan/beeid/notebooks/cmc_experiments/models3/211006{:04}_untagged_augmentation_simplecnnv2_convb3_dim_128/model.tf\".format(ntrack)\n",
    "    shortterm_mean_dist, short_distribution, longterm_mean_dist, long_distribution, notsame_mean_dist, notsame_distribution = eval_model_short_long_term(model_path)\n",
    "\n",
    "    benchmark[ntrack][\"shortterm_mean\"] = shortterm_mean_dist\n",
    "    benchmark[ntrack][\"longterm_mean\"] = longterm_mean_dist\n",
    "    benchmark[ntrack][\"shortterm_hist\"] = short_distribution\n",
    "    benchmark[ntrack][\"longterm_hist\"] = long_distribution\n",
    "    benchmark[ntrack][\"notsame_mean\"] = notsame_mean_dist\n",
    "    benchmark[ntrack][\"notsame_hist\"] = notsame_distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ntrack in ntracks:\n",
    "    print(ntrack, benchmark[ntrack]['shortterm_mean'], benchmark[ntrack]['longterm_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=3, sharex=True, sharey=True, figsize=(16, 8))\n",
    "axes = ax.ravel()\n",
    "for i, ntrack in enumerate(ntracks):\n",
    "    axes[i].set_title(\"ntracks: {}\".format(ntrack))\n",
    "    axes[i].hist(benchmark[ntrack][\"shortterm_hist\"], label=\"shortterm\", color=\"tab:blue\", density=True, alpha=0.7)\n",
    "    axes[i].axvline(benchmark[ntrack][\"shortterm_mean\"], color=\"tab:blue\", label=\"shortterm\")\n",
    "    \n",
    "    axes[i].hist(benchmark[ntrack][\"longterm_hist\"], label=\"longterm\", color=\"tab:orange\", density=True, alpha=0.7)\n",
    "    axes[i].axvline(benchmark[ntrack][\"longterm_mean\"], color=\"tab:orange\", label=\"longterm\")\n",
    "    \n",
    "    axes[i].hist(benchmark[ntrack][\"notsame_hist\"], label=\"notsame\", color=\"tab:red\", density=True, alpha=0.7)\n",
    "    axes[i].axvline(benchmark[ntrack][\"notsame_mean\"], color=\"tab:red\", label=\"notsame\")\n",
    "plt.tight_layout()\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-venture",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bees",
   "language": "python",
   "name": "bees"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
