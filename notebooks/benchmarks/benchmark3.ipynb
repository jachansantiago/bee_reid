{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "minimal-serbia",
   "metadata": {},
   "source": [
    "# Contrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "governing-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "# from tensorflow_addons.losses import TripletSemiHardLoss, TripletHardLoss\n",
    "\n",
    "from beeid.utils import sensitivity_map\n",
    "\n",
    "from code.models import simple_cnnv2, ContrastiveLearning\n",
    "from code.data_utils import load_tf_pair_dataset, load_tf_dataset\n",
    "from code.viz import show_sensitivity_maps\n",
    "from code.evaluation import cmc_evaluation, plot_cmc\n",
    "from code.evaluation import get_interactive_plot_query_gallery\n",
    "\n",
    "# IMAGE_FOLDER = \"/mnt/storage/work/jchan/normalized_uncensored_dataset/images/\"\n",
    "# DATASET_CSV = \"/mnt/storage/work/jchan/body_dataset2/dataset3.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-knight",
   "metadata": {},
   "source": [
    "### Prepare dataset\n",
    "\n",
    "Select the dates for Training, Validation and Testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mental-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "valid_df = pd.read_csv(\"data/valid.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-dictionary",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sorted-couple",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_gallery(query, query_df, dfGroupedbyTagId, limit=None):\n",
    "    same_tag = (query_df.track_tag_id == query.track_tag_id)\n",
    "    different_global_track = (query_df.global_track_id != query.global_track_id)\n",
    "    same_tag_pool = query_df[same_tag & different_global_track]\n",
    "    key = same_tag_pool.sample().iloc[0]\n",
    "\n",
    "    negatives = dfGroupedbyTagId.apply(lambda x: x.iloc[np.random.randint(len(x))])\n",
    "    different_tag = (negatives.index != query.track_tag_id)\n",
    "    negatives = negatives[different_tag]\n",
    "    \n",
    "    if limit is not None:\n",
    "        negatives = negatives.sample(limit)\n",
    "    query_gallery = np.concatenate(([query.filename, key.filename], negatives.filename.values))\n",
    "    return query_gallery\n",
    "\n",
    "def cmc_dataset(df, iterations=100, gallery_size=None):\n",
    "    \"\"\"\n",
    "    model: keras model\n",
    "    df: a dataframe with the image to evaluate\n",
    "    \n",
    "    \"\"\"\n",
    "    cdf = df.copy()\n",
    "    \n",
    "    query_df = cdf.groupby(\"track_tag_id\").filter(lambda x: len(x[\"global_track_id\"].unique()) > 1)\n",
    "    dfGroupedbyTagId = cdf.groupby(\"track_tag_id\")\n",
    "    \n",
    "    iteration_ids = list()\n",
    "    query_ids = list()\n",
    "    image_ids = list()\n",
    "    galleries = list()\n",
    "\n",
    "    for it in tqdm(range(iterations)):\n",
    "        queries = query_df.groupby(\"track_tag_id\").sample()\n",
    "        queries_and_galleries = list()\n",
    "        for j, (i, query_data) in enumerate(queries.iterrows()):\n",
    "            query_gallery =  get_query_gallery(query_data, query_df, dfGroupedbyTagId, limit=gallery_size)\n",
    "            queries_and_galleries.append(query_gallery)\n",
    "            \n",
    "            iteration_ids.append(np.ones(len(query_gallery)) * it)\n",
    "            query_ids.append(np.ones(len(query_gallery)) * j)\n",
    "            image_ids.append(np.arange(0, len(query_gallery)))\n",
    "            galleries.append(query_gallery)\n",
    "    \n",
    "    iteration_ids = np.array(iteration_ids).ravel().astype(int)\n",
    "    query_ids = np.array(query_ids).ravel().astype(int)\n",
    "    image_ids = np.array(image_ids).ravel()\n",
    "    galleries = np.array(galleries).ravel()\n",
    "    \n",
    "    df = pd.DataFrame({\"iteration_id\":iteration_ids, \"gallery_id\":query_ids, \"image_id\": image_ids,  \"filename\":galleries})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "banned-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS=1000\n",
    "GALLERY_SIZE=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-jerusalem",
   "metadata": {},
   "source": [
    "### Evaluation on ids shared with the training set (validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "conservative-stylus",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [11:52<00:00,  1.40it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ids = train_df.track_tag_id.unique()\n",
    "\n",
    "valid_with_shared_ids = valid_df[valid_df.track_tag_id.isin(train_ids)]\n",
    "\n",
    "df = cmc_dataset(valid_with_shared_ids, iterations=ITERATIONS, gallery_size=GALLERY_SIZE)\n",
    "\n",
    "df.to_csv(\"data/valid_with_shared_ids.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-lafayette",
   "metadata": {},
   "source": [
    "### Evaluation on ids shared with the whole validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "distributed-italian",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [19:11<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "df = cmc_dataset(valid_df, iterations=ITERATIONS, gallery_size=GALLERY_SIZE)\n",
    "\n",
    "df.to_csv(\"data/valid_galleries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-sierra",
   "metadata": {},
   "source": [
    "### Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "possible-termination",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:13:14<00:00,  4.39s/it]\n"
     ]
    }
   ],
   "source": [
    "df = cmc_dataset(test_df, iterations=ITERATIONS, gallery_size=GALLERY_SIZE)\n",
    "\n",
    "df.to_csv(\"data/test_galleries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "foreign-london",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set has 126 Ids.\n",
      "Intersection of train and test set 29\n"
     ]
    }
   ],
   "source": [
    "train_ids = train_df.track_tag_id.unique()\n",
    "test_ids = test_df.track_tag_id.unique()\n",
    "\n",
    "\n",
    "intersection = set(train_ids) & set(test_ids)\n",
    "\n",
    "print(\"Test set has {} Ids.\".format(len(test_ids)))\n",
    "print(\"Intersection of train and test set {}\".format(len(intersection)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-action",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 587/1000 [26:25<18:34,  2.70s/it]"
     ]
    }
   ],
   "source": [
    "test_disjoint_train = test_df[~test_df.track_tag_id.isin(train_ids)]\n",
    "\n",
    "df = cmc_dataset(test_disjoint_train, iterations=ITERATIONS, gallery_size=GALLERY_SIZE)\n",
    "\n",
    "df.to_csv(\"data/test_no_train_overlap.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bees",
   "language": "python",
   "name": "bees"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
