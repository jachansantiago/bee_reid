{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "returning-dryer",
   "metadata": {},
   "source": [
    "# Contrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "green-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "# from tensorflow_addons.losses import TripletSemiHardLoss, TripletHardLoss\n",
    "\n",
    "from beeid.utils import sensitivity_map\n",
    "\n",
    "from code.models import simple_cnnv2, ContrastiveLearning\n",
    "from code.data_utils import load_tf_pair_dataset, load_tf_dataset\n",
    "from code.viz import show_sensitivity_maps\n",
    "from code.evaluation import cmc_evaluation, plot_cmc\n",
    "from code.evaluation import get_interactive_plot_query_gallery\n",
    "\n",
    "# IMAGE_FOLDER = \"/mnt/storage/work/jchan/normalized_uncensored_dataset/images/\"\n",
    "# DATASET_CSV = \"/mnt/storage/work/jchan/body_dataset2/dataset3.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-petersburg",
   "metadata": {},
   "source": [
    "### Prepare dataset\n",
    "\n",
    "Select the dates for Training, Validation and Testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "public-delight",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "valid_df = pd.read_csv(\"data/valid.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-greek",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmc_evaluation(model, df, iterations=100, gallery_size=10):\n",
    "    \"\"\"\n",
    "    model: keras model\n",
    "    df: a dataframe with the image to evaluate\n",
    "    \n",
    "    \"\"\"\n",
    "    cdf = df.copy()\n",
    "    \n",
    "    query_df = cdf.groupby(\"track_tag_id\").filter(lambda x: len(x[\"global_track_id\"].unique()) > 1)\n",
    "    dfGroupedbyTagId = cdf.groupby(\"track_tag_id\")\n",
    "    \n",
    "    ranks = np.zeros((iterations, gallery_size))\n",
    "\n",
    "    for it in tqdm(range(iterations)):\n",
    "        queries = query_df.groupby(\"track_tag_id\").sample()\n",
    "        queries_and_galleries = list()\n",
    "        for i, query_data in queries.iterrows():\n",
    "            query_gallery =  get_query_gallery(query_data, query_df, dfGroupedbyTagId, limit=gallery_size)\n",
    "            queries_and_galleries.append(query_gallery)\n",
    "\n",
    "        queries_and_galleries = np.array(queries_and_galleries).ravel()\n",
    "\n",
    "        images = filename2image(queries_and_galleries)\n",
    "        predictions = model.predict(images.batch(32))\n",
    "\n",
    "        query_gallery_size = gallery_size + 2\n",
    "        queries_emb = predictions[::query_gallery_size]\n",
    "\n",
    "        pred_idx = np.arange(0, len(predictions))\n",
    "        galleries_emb = predictions[np.mod(pred_idx, query_gallery_size) != 0]\n",
    "\n",
    "        queries_emb = queries_emb.reshape(len(queries), 1, -1)\n",
    "        galleries_emb = galleries_emb.reshape(len(queries), query_gallery_size - 1, -1 )\n",
    "\n",
    "        # Calucluate distance\n",
    "        cos_dist = tf.matmul(queries_emb, galleries_emb, transpose_b=True).numpy()\n",
    "        euclid_dist = -(cos_dist - 1)\n",
    "\n",
    "        # Calculate Rank\n",
    "        r = np.argmin(np.argsort(euclid_dist), axis=2)\n",
    "        r = np.squeeze(r)\n",
    "\n",
    "        for i in range(gallery_size):\n",
    "            ranks[it][i] = np.mean(r < (i + 1))\n",
    "    return np.mean(ranks, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS=100\n",
    "GALLERY_SIZE=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-ending",
   "metadata": {},
   "source": [
    "### Evaluation on ids shared with the training set (validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = train_df.track_tag_id.unique()\n",
    "\n",
    "valid_with_shared_ids = valid_df[valid_df.track_tag_id.isin(train_ids)]\n",
    "\n",
    "valid_with_shared_ids_ranks_means = cmc_evaluation(model, valid_with_shared_ids, iterations=ITERATIONS, gallery_size=GALLERY_SIZE)\n",
    "\n",
    "plot_cmc(valid_with_shared_ids_ranks_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-canberra",
   "metadata": {},
   "source": [
    "### Evaluation on ids shared with the whole validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ranks_means = cmc_evaluation(model, valid_df, iterations=ITERATIONS, gallery_size=GALLERY_SIZE)\n",
    "\n",
    "plot_cmc(valid_ranks_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-antique",
   "metadata": {},
   "source": [
    "### Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ranks_means = cmc_evaluation(model, test_df, iterations=ITERATIONS, gallery_size=GALLERY_SIZE)\n",
    "\n",
    "plot_cmc(test_ranks_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = train_df.track_tag_id.unique()\n",
    "test_ids = test_df.track_tag_id.unique()\n",
    "\n",
    "\n",
    "intersection = set(train_ids) & set(test_ids)\n",
    "\n",
    "print(\"Test set has {} Ids.\".format(len(test_ids)))\n",
    "print(\"Intersection of train and test set {}\".format(len(intersection)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_disjoint_train = test_df[~test_df.track_tag_id.isin(train_ids)]\n",
    "\n",
    "test_disjoint_train_ranks_means = cmc_evaluation(model, test_disjoint_train, iterations=ITERATIONS, gallery_size=GALLERY_SIZE)\n",
    "\n",
    "plot_cmc(test_disjoint_train_ranks_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-finding",
   "metadata": {},
   "source": [
    "#### Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dict = dict()\n",
    "\n",
    "metric_dict[\"valid_cmc_only_train_ids\"] = valid_with_shared_ids_ranks_means \n",
    "metric_dict[\"valid_cmc\"] = valid_ranks_means\n",
    "metric_dict[\"test_cmc\"] = test_ranks_means\n",
    "metric_dict[\"test_cmc_no_ids_overlap\"] = test_disjoint_train_ranks_means\n",
    "\n",
    "metric_df = pd.DataFrame(metric_dict)\n",
    "metric_df.to_csv(\"results/contrastive_lossT1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-overhead",
   "metadata": {},
   "source": [
    "#### Interactive Query Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fleet-matrix",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96bb4040cfe4c15a0d5ac07f74cf487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=17, description='query_id', max=34), Checkbox(value=False, description='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_interactive_plot_query_gallery(model, valid_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bees",
   "language": "python",
   "name": "bees"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
